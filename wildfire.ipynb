{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-28T20:39:35.658588Z",
     "iopub.status.busy": "2025-09-28T20:39:35.658311Z",
     "iopub.status.idle": "2025-09-28T20:41:29.430827Z",
     "shell.execute_reply": "2025-09-28T20:41:29.430075Z",
     "shell.execute_reply.started": "2025-09-28T20:39:35.658559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install matplotlib seaborn pandas numpy\n",
    "!pip install kaggle\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T20:42:19.031641Z",
     "iopub.status.busy": "2025-09-28T20:42:19.031354Z",
     "iopub.status.idle": "2025-09-28T20:42:19.599886Z",
     "shell.execute_reply": "2025-09-28T20:42:19.599062Z",
     "shell.execute_reply.started": "2025-09-28T20:42:19.031622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For Kaggle Notebook - Dataset is already available in /kaggle/input\n",
    "import os\n",
    "\n",
    "# Set the dataset path\n",
    "dataset_path = '/kaggle/input/the-wildfire-dataset/the_wildfire_dataset_2n_version'\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "# Explore the structure\n",
    "print(\"Dataset structure:\")\n",
    "for split in ['test', 'train', 'val']:\n",
    "    split_path = os.path.join(dataset_path, split)\n",
    "    if os.path.exists(split_path):\n",
    "        print(f\"\\nüìÅ {split}/\")\n",
    "        for class_name in ['fire', 'nofire']:\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if os.path.exists(class_path):\n",
    "                num_images = len([f for f in os.listdir(class_path) \n",
    "                                if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "                print(f\"  üìÅ {class_name}/: {num_images} images\")\n",
    "\n",
    "# Count total images\n",
    "total_images = 0\n",
    "for split in ['test', 'train', 'val']:\n",
    "    for class_name in ['fire', 'nofire']:\n",
    "        class_path = os.path.join(dataset_path, split, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            images = [f for f in os.listdir(class_path) \n",
    "                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            total_images += len(images)\n",
    "            print(f\"{split}/{class_name}: {len(images)} images\")\n",
    "\n",
    "print(f\"\\nTotal images: {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T20:42:31.591593Z",
     "iopub.status.busy": "2025-09-28T20:42:31.591333Z",
     "iopub.status.idle": "2025-09-28T20:42:31.598963Z",
     "shell.execute_reply": "2025-09-28T20:42:31.598112Z",
     "shell.execute_reply.started": "2025-09-28T20:42:31.591574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class WildfireBinaryDataset(Dataset):\n",
    "    def __init__(self, data_dir, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        Dataset for binary classification (fire vs nofire)\n",
    "        \n",
    "        Args:\n",
    "            data_dir: Root directory of the dataset\n",
    "            split: One of 'train', 'test', 'val'\n",
    "            transform: Image transformations\n",
    "        \"\"\"\n",
    "        self.data_dir = os.path.join(data_dir, split)\n",
    "        self.transform = transform\n",
    "        self.classes = ['nofire', 'fire']  # Important: nofire=0, fire=1\n",
    "        self.class_to_idx = {'nofire': 0, 'fire': 1}\n",
    "        \n",
    "        # Collect all image paths and labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                        self.labels.append(self.class_to_idx[class_name])\n",
    "        \n",
    "        print(f\"Found {len(self.image_paths)} images in {split} split\")\n",
    "        print(f\"Class distribution:\")\n",
    "        for class_name in self.classes:\n",
    "            count = sum(1 for label in self.labels if label == self.class_to_idx[class_name])\n",
    "            print(f\"  {class_name}: {count} images ({count/len(self.labels)*100:.1f}%)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T20:42:34.511441Z",
     "iopub.status.busy": "2025-09-28T20:42:34.510863Z",
     "iopub.status.idle": "2025-09-28T20:42:34.532711Z",
     "shell.execute_reply": "2025-09-28T20:42:34.532001Z",
     "shell.execute_reply.started": "2025-09-28T20:42:34.511415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define data transformations for binary classification\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Create datasets for all splits\n",
    "train_dataset = WildfireBinaryDataset(dataset_path, split='train', transform=data_transforms['train'])\n",
    "val_dataset = WildfireBinaryDataset(dataset_path, split='val', transform=data_transforms['val'])\n",
    "test_dataset = WildfireBinaryDataset(dataset_path, split='test', transform=data_transforms['test'])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"\\nData loaders created:\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {len(train_dataset.classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T20:42:38.280110Z",
     "iopub.status.busy": "2025-09-28T20:42:38.279842Z",
     "iopub.status.idle": "2025-09-28T20:42:38.858240Z",
     "shell.execute_reply": "2025-09-28T20:42:38.857372Z",
     "shell.execute_reply.started": "2025-09-28T20:42:38.280092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_binary_model():\n",
    "    \"\"\"Create a MobileNetV2 model for binary classification\"\"\"\n",
    "    # Load pre-trained MobileNetV2\n",
    "    model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    # Freeze early layers for transfer learning\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace the classifier for binary classification\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(model.last_channel, 1),  # Single output for binary classification\n",
    "        nn.Sigmoid()  # Sigmoid activation for binary classification\n",
    "    )\n",
    "    \n",
    "    # Unfreeze the classifier parameters\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_binary_model()\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Binary classification model created successfully!\")\n",
    "print(f\"Model architecture:\\n{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T20:42:58.595538Z",
     "iopub.status.busy": "2025-09-28T20:42:58.595247Z",
     "iopub.status.idle": "2025-09-28T21:08:37.568804Z",
     "shell.execute_reply": "2025-09-28T21:08:37.567717Z",
     "shell.execute_reply.started": "2025-09-28T20:42:58.595518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_binary_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                outputs = model(images)\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_wildfire_model.pth')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Loss: {running_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {train_accuracy:.2f}%, '\n",
    "              f'Val Acc: {val_accuracy:.2f}%')\n",
    "    \n",
    "    return train_losses, val_accuracies\n",
    "\n",
    "# Use Binary Cross Entropy Loss for binary classification\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "print(\"Starting training for binary classification...\")\n",
    "train_losses, val_accuracies = train_binary_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, num_epochs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T21:20:33.716118Z",
     "iopub.status.busy": "2025-09-28T21:20:33.715804Z",
     "iopub.status.idle": "2025-09-28T21:22:08.296883Z",
     "shell.execute_reply": "2025-09-28T21:22:08.295998Z",
     "shell.execute_reply.started": "2025-09-28T21:20:33.716095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_binary_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            probabilities = outputs.cpu().numpy()\n",
    "            predicted = (outputs > 0.5).float().cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(predicted.flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "            all_probabilities.extend(probabilities.flatten())\n",
    "    \n",
    "    return all_preds, all_labels, all_probabilities\n",
    "\n",
    "# Evaluate on test set\n",
    "all_preds, all_labels, all_probabilities = evaluate_binary_model(model, test_loader)\n",
    "\n",
    "# Convert to integers for classification report\n",
    "all_preds_int = [int(p) for p in all_preds]\n",
    "all_labels_int = [int(l) for l in all_labels]\n",
    "\n",
    "# Classification report\n",
    "class_names = ['nofire', 'fire']\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels_int, all_preds_int, target_names=class_names))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(all_labels_int, all_preds_int)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix - Binary Classification')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3655844,
     "sourceId": 7863205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
